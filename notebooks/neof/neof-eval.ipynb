{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81df4220-71d6-4e9d-acdf-573c054931eb",
   "metadata": {},
   "source": [
    "# NeOF Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b35fd0c0-8808-40cc-baba-d836ee13cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from neural_orientation_field.neof.dataset import NeOFImageDataset\n",
    "from neural_orientation_field.neof.model import NeOFCoarseModel, NeOFFineModel\n",
    "from neural_orientation_field.nerf.utils import cam_ray_from_pose\n",
    "from neural_orientation_field.neof.utils import nerf_image_render, hair_dir_vec2color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01037bcf-1466-4847-a662-019fbc5db499",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use MPS device.\n",
    "USE_DEVICE = \"mps\"\n",
    "\n",
    "if USE_DEVICE == \"mps\" and torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif USE_DEVICE == \"cuda\" and torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57eb2e5-f059-42a5-aba8-35f27255a1bc",
   "metadata": {},
   "source": [
    "# Load Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9e58b5-ffd3-405c-864b-e4bef0fead6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/images/blender-hair-long-test/body_mask'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/images/blender-hair-long-test/hair_mask'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/images/blender-hair-long-test/hair_dir'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/cameras/blender-hair-long-test/frame-names.txt'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/cameras/blender-hair-long-test/camera-transforms.npy'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/cameras/blender-hair-long-test/camera-params.npy'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/models/neof/blender-hair-long'),\n",
       " PosixPath('/Users/fangjun/Documents/stanford/cs229/final-project/data/evals/neof/blender-hair-long'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "BODY_MASK_PATH = \"../../data/images/blender-hair-long-test/body_mask/\"\n",
    "HAIR_MASK_PATH = \"../../data/images/blender-hair-long-test/hair_mask/\"\n",
    "HAIR_DIR_PATH = \"../../data/images/blender-hair-long-test/hair_dir/\"\n",
    "CAMERA_PATH = \"../../data/cameras/blender-hair-long-test/\"\n",
    "CHECKPOINT_PATH = \"../../data/models/neof/blender-hair-long/\"\n",
    "OUTPUT_PATH = \"../../data/evals/neof/blender-hair-long\"\n",
    "\n",
    "body_mask_path = pathlib.Path(BODY_MASK_PATH).resolve()\n",
    "if not body_mask_path.exists():\n",
    "    raise FileNotFoundError(\"Body mask path doesn't exist.\")\n",
    "hair_mask_path = pathlib.Path(HAIR_MASK_PATH).resolve()\n",
    "if not hair_mask_path.exists():\n",
    "    raise FileNotFoundError(\"Hair mask path doesn't exist.\")\n",
    "hair_dir_path = pathlib.Path(HAIR_DIR_PATH).resolve()\n",
    "if not hair_dir_path.exists():\n",
    "    raise FileNotFoundError(\"Hair directory path doesn't exist.\")\n",
    "camera_path = pathlib.Path(CAMERA_PATH).resolve()\n",
    "if not camera_path.exists():\n",
    "    raise FileNotFoundError(\"Camera path doesn't exist.\")\n",
    "checkpoint_path = pathlib.Path(CHECKPOINT_PATH).resolve()\n",
    "if not checkpoint_path.exists():\n",
    "    raise FileNotFoundError(\"Checkpoint path doesn't exist.\")\n",
    "output_path = pathlib.Path(OUTPUT_PATH).resolve()\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "frame_name_path = camera_path / \"frame-names.txt\"\n",
    "cam_transform_path = camera_path / \"camera-transforms.npy\"\n",
    "cam_param_path = camera_path / \"camera-params.npy\"\n",
    "\n",
    "body_mask_path, hair_mask_path, hair_dir_path, frame_name_path, cam_transform_path, cam_param_path, checkpoint_path, output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f60273-8ea3-4ad5-ba82-b15b8f894e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(frame_name_path, \"r\") as frame_path_file:\n",
    "    frame_names = frame_path_file.read().split(\"\\n\")\n",
    "    body_mask_paths = [body_mask_path / frame_name for frame_name in frame_names]\n",
    "    hair_mask_paths = [hair_mask_path / frame_name for frame_name in frame_names]\n",
    "    hair_dir_paths = [hair_dir_path / frame_name for frame_name in frame_names]\n",
    "with open(cam_transform_path, \"rb\") as cam_transform_file:\n",
    "    cam_transforms = np.load(cam_transform_file)\n",
    "with open(cam_param_path, \"rb\") as cam_param_file:\n",
    "    cam_params = np.load(cam_param_file)\n",
    "\n",
    "image_dataset = NeOFImageDataset(body_mask_paths, hair_mask_paths, hair_dir_paths, cam_params, cam_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c790c-f02e-43d6-852c-100ee5891b7b",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "307e7c04-82c1-4739-bc49-ed051f1229c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params_file_name = \"model_params.pth\"\n",
    "coarse_model_file_name = \"coarse_final.pth\"\n",
    "fine_model_file_name = \"fine_final.pth\"\n",
    "\n",
    "# Load model params.\n",
    "model_params = torch.load(checkpoint_path / model_params_file_name, weights_only=True)\n",
    "\n",
    "coarse_pos_encode = model_params[\"coarse_pos_encode\"]\n",
    "fine_pos_encode = model_params[\"fine_pos_encode\"]\n",
    "nc = model_params[\"nc\"]\n",
    "fc = model_params[\"fc\"]\n",
    "samples_per_ray = model_params[\"samples_per_ray\"]\n",
    "max_subd_samples = model_params[\"max_subd_samples\"]\n",
    "\n",
    "# Load model.\n",
    "coarse_model = NeOFCoarseModel(num_encoding_functions=coarse_pos_encode)\n",
    "coarse_model.to(device)\n",
    "fine_model = NeOFFineModel(num_encoding_functions=fine_pos_encode)\n",
    "fine_model.to(device)\n",
    "\n",
    "coarse_model.load_state_dict(torch.load(checkpoint_path / coarse_model_file_name, weights_only=True, map_location=device))\n",
    "fine_model.load_state_dict(torch.load(checkpoint_path / fine_model_file_name, weights_only=True, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e2de6-cf18-4b2c-b30c-df35e6d439c6",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2565ccab-8bd6-48b5-a0ba-f63aa90d6e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime parameters.\n",
    "ray_batch_size = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8145622-61b6-4be9-b927-164bd1fc5b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab21457d9b491daad9aefa9b203efd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_vecs = []\n",
    "pred_vecs = []\n",
    "for (_, _, test_vec), cam_transform, (h, w), (f, cx, cy) in tqdm(image_dataset):\n",
    "    cam_orig, cam_ray_world = cam_ray_from_pose(cam_transform, h, w, f, cx, cy)\n",
    "    _, fine_pred = nerf_image_render(\n",
    "        coarse_model,\n",
    "        fine_model,\n",
    "        cam_transform,\n",
    "        cam_orig,\n",
    "        cam_ray_world,\n",
    "        ray_batch_size,\n",
    "        nc,\n",
    "        fc,\n",
    "        samples_per_ray,\n",
    "        max_subd_samples,\n",
    "        coarse_pos_encode,\n",
    "        fine_pos_encode,\n",
    "        device\n",
    "    )\n",
    "    test_vecs.append(test_vec)\n",
    "    pred_vecs.append(fine_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872a2572-cc96-4bda-8d38-c859bb828608",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = [hair_dir_vec2color(test_vec) for test_vec in test_vecs]\n",
    "pred_images = [hair_dir_vec2color(pred_vec) for pred_vec in pred_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0be2597-7959-429a-8faa-d0efbc2f16cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d31b000016448b68b76f5fe6ff1eb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_images))):\n",
    "    test_image = Image.fromarray((test_images[i] * 255).astype(np.uint8))\n",
    "    test_image.save(output_path / f\"test_{i}.png\")\n",
    "    pred_image = Image.fromarray((pred_images[i] * 255).astype(np.uint8))\n",
    "    pred_image.save(output_path / f\"pred_{i}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
